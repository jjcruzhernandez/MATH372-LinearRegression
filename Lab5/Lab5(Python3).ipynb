{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Hitters (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the computational section of this Lab you will consider the baseball dataset found in the file hitters.csv. This dataset records the salary of ùëõ = 263 Major League Baseball players during the 1987 season as well as ùëû = 19 statistics associated with the performance of each player during the previous season. Specifically, the dataset contains observations from the following variables:\n",
    "* AtBat: Number of times at bat in 1986\n",
    "* Hits: Number of hits in 1986\n",
    "* HmRun: Number of home runs in 1986\n",
    "* Runs: Number of runs in 1986\n",
    "* RBI: Number of runs batted in in 1986\n",
    "* Walks: Number of walks in 1986\n",
    "* Years: Number of years in the major leagues\n",
    "* CAtBat: Number of times at bat during his career\n",
    "* CHits: Number of hits during his career\n",
    "* CHmRun: Number of home runs during his career\n",
    "* CRuns: Number of runs during his career\n",
    "* CRBI: Number of runs batted in during his career\n",
    "* CWalks: Number of walks during his career\n",
    "* League: A categorical variable with levels A (for American) and N (for National) indicating the player‚Äôs league at the end of 1986\n",
    "* Division: A factor with levels E (for East) and W (for West) indicating the player‚Äôs division at the end of 1986\n",
    "* PutOuts: Number of put outs in 1986\n",
    "* Assists: Number of assists in 1986\n",
    "* Errors: Number of errors in 1986\n",
    "* Salary: 1987 annual salary on opening day in thousands of dollars\n",
    "* NewLeague: A factor with levels A and N indicating the player‚Äôs league at the beginning of 1987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jencruz/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "data = pd.read_csv('hitters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Calculate the variance inflation factor (VIF) for each of the explanatory variables.Comment on whether multicollinearity appears to be an issue. If it is, identify the three explanatory variables that are most seriously affected by the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Division</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PutOuts</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errors</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assists</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewLeague</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>League</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walks</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HmRun</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBI</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CWalks</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AtBat</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHmRun</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRBI</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRuns</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAtBat</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHits</th>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "Division     1\n",
       "PutOuts      1\n",
       "Errors       2\n",
       "Assists      2\n",
       "NewLeague    4\n",
       "League       4\n",
       "Walks        4\n",
       "HmRun        7\n",
       "Years        9\n",
       "RBI         11\n",
       "Runs        15\n",
       "CWalks      19\n",
       "AtBat       22\n",
       "Hits        30\n",
       "CHmRun      46\n",
       "CRBI       131\n",
       "CRuns      161\n",
       "CAtBat     198\n",
       "CHits      490"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "League = pd.get_dummies(data['League'])\n",
    "Division = pd.get_dummies(data['Division'])\n",
    "NewLeague = pd.get_dummies(data['NewLeague'])\n",
    "data = data.drop(['League', 'Division', 'NewLeague'], axis = 1)\n",
    "data = pd.concat([data, League['N'], Division['W'], NewLeague['N']], axis = 1)\n",
    "data.columns = ['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat', 'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists', 'Errors', 'Salary', 'League', 'Division', 'NewLeague']\n",
    "X = data.drop(['Salary'], axis = 1)\n",
    "y = data['Salary']\n",
    "col = X.columns\n",
    "vif = np.repeat(0,19)\n",
    "for i in range(19):    \n",
    "    m = smf.ols(col[i] + '~' + col[0] + '+' + col[1] + '+' + col[2] + '+' + col[3] + '+' + col[4] + '+' + col[5] + '+' + col[7] + '+' + col[7] + '+' + col[8] + '+' + col[9] + '+' + col[10] + '+' + col[11] + '+' + col[12] + '+' + col[13] + '+' + col[14] + '+' + col[15] + '+' + col[16] + '+' + col[17] + '+' + col[18] + '-' + col[i], data = X).fit()\n",
    "    vif[i] = 1/(1-m.rsquared)\n",
    "vif = pd.DataFrame(vif, col)\n",
    "vif.sort_values([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the VIFs that were calculated above, we can see that multicollinearity is an issue. The top variables that are seriously affectd by this issue are: CRBI, CRuns, CAtBat, and Chits. These all have large VIFs, but this is not suprising since the # of runs scored and RBIs ina player's career are both going to be highly correlated with the # of hits the player gets in their career. And these will be highly correlated with # of times a player gets to bat in their career."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Using the all-possible-subsets approach, find the model that best fits the observed data. This procedure may be automated using the regsubsets() function in R, but you must explain in your own words how this algorithm identifies the ‚Äòbest' model. Note that you do not need to perform this task in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need to perform in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Using the forward-stepwise-selection approach, find the model that best fits the observed data. This procedure may be automated using the stepAIC() function in R, but you must explain in your own words how this algorithm identifies the ‚Äòbest‚Äô model. Note that you do not need to perform this task in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need to perform in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Using the backward-stepwise-selection approach, find the model that best fits the observed data. This procedure may be automated using the stepAIC() function in R, but you must explain in your own words how this algorithm identifies the ‚Äòbest‚Äô model. Note that you do not need to perform this task in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need to perform in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Using the hybrid-stepwise-selection approach, find the model that best fits the observed data. This procedure may be automated using the stepAIC() function in R, but you must explain in your own words how this algorithm identifies the ‚Äòbest‚Äô model. Note that you do not need to perform this task in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need to perform in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) In this part you will compare the predictive performance of four models:\n",
    "\n",
    "* i. The full model with all 19 explanatory variables.\n",
    "* ii. The optimal model identified in part (b).\n",
    "* iii. The best model from parts (c)-(e) (i.e., the best stepwise-selection model).\n",
    "* iv. The model that is considered optimal with respect to the Bayesian Information Criterion (BIC) which contains the variables AtBat, Hits, Walks, CRBI, Division and PutOuts.\n",
    "\n",
    "Randomly split the observed data into a training set (containing roughly 80% of all of the data) and a held-out test set (containing roughly 20% of all of the data). Calculate the predictive root-mean-square error (RMSE) for each of the four models. Which model appears to be most appropriate? Justify why this model is most appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictive RMSE for the full model is 330.9044\n",
      "The predictive RMSE for the optimal model from part (b) is  307.9706\n",
      "The predictive RMSE for the best model selected by stepwise selection is  308.126\n",
      "The predictive RMSE for the optimal model (in terms of BIC) is  286.7861\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "#i. The full model with all 19 explanatory variables.\n",
    "model1 = smf.ols('Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + League + Division + NewLeague + PutOuts + Assists + Errors', data = train).fit()\n",
    "pred1 = model1.predict(X_test)\n",
    "RMSE1 = np.sqrt(np.mean((y_test - pred1)**2))\n",
    "print('The predictive RMSE for the full model is', np.round(RMSE1, 4))\n",
    "\n",
    "#ii. The optimal model identified in part (b).\n",
    "model2 = smf.ols('Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + League + Division + PutOuts + Assists', data = train).fit()\n",
    "pred2 = model2.predict(X_test)\n",
    "RMSE2 = np.sqrt(np.mean((y_test - pred2)**2))\n",
    "print('The predictive RMSE for the optimal model from part (b) is ', np.round(RMSE2, 4))\n",
    "\n",
    "#iii. The best model from parts (c)-(e) (i.e., the best stepwise-selection model).\n",
    "model3 = smf.ols('Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks + CWalks + CRuns + CAtBat + Assists', data = train).fit()\n",
    "pred3 = model3.predict(X_test)\n",
    "RMSE3 = np.sqrt(np.mean((y_test - pred3)**2))\n",
    "print('The predictive RMSE for the best model selected by stepwise selection is ', round(RMSE3, 4))\n",
    "\n",
    "#iv. The model that is considered optimal with respect to the Bayesian Information Criterion (BIC) which contains the variables AtBat, Hits, Walks, CRBI, Division and PutOuts.\n",
    "model4 = smf.ols('Salary ~ AtBat + Hits + Walks + CRBI + Division + PutOuts', data = train).fit()\n",
    "pred4 = model4.predict(X_test)\n",
    "RMSE4 = np.sqrt(np.mean((y_test - pred4)**2))\n",
    "print('The predictive RMSE for the optimal model (in terms of BIC) is ', round(RMSE4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the RMSE, the best predicitive model is the optimal BIC model since it has the smallest RMSE. In contrast, the worst predicitive model is the full model since it has the largest RMSE. And both the optimal model from part (b) and the stepwise selection mdoel perform similarly since the difference between both there RMSE values is very small and they perform only almost as well asn the optimal BIC model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) As in part (f), you must compare the predictive performance of the same four models, but here you must determine the predictive accuracy (predictive RMSE) by using 10-Fold Cross Validation. Which model appears to be most appropriate? Justify why this model is most appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictive RMSE for the full model is 344.2269\n",
      "The predictive RMSE for the optimal model from part (b) is  329.0459\n",
      "The predictive RMSE for the best model selected by stepwise selection is  330.5032\n",
      "The predictive RMSE for the optimal model (in terms of BIC) is  328.7458\n"
     ]
    }
   ],
   "source": [
    "numfolds = 10\n",
    "n = data.shape[0]\n",
    "\n",
    "#i. The full model with all 19 explanatory variables.\n",
    "kf = KFold(n=n, n_folds=numfolds, shuffle = True)\n",
    "MSE = 0\n",
    "for train_indices, test_indices in kf:\n",
    "    train_X = X.iloc[train_indices, :]; train_y = y[train_indices]\n",
    "    test_X = X.iloc[test_indices, :]; test_y = y[test_indices]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    m = smf.ols('Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + League + Division + NewLeague + PutOuts + Assists + Errors', data = training).fit()   \n",
    "    pred = m.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE1 = np.sqrt(MSE/numfolds)\n",
    "print('The predictive RMSE for the full model is', np.round(RMSE1, 4))\n",
    "\n",
    "#ii. The optimal model identified in part (b).\n",
    "kf = KFold(n=n, n_folds=numfolds, shuffle = True)\n",
    "MSE = 0\n",
    "for train_indices, test_indices in kf:\n",
    "    train_X = X.iloc[train_indices, :]; train_y = y[train_indices]\n",
    "    test_X = X.iloc[test_indices, :]; test_y = y[test_indices]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    m = smf.ols('Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + League + Division + PutOuts + Assists', data = training).fit()   \n",
    "    pred = m.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE2 = np.sqrt(MSE/numfolds)\n",
    "print('The predictive RMSE for the optimal model from part (b) is ', np.round(RMSE2, 4))\n",
    "\n",
    "#iii. The best model from parts (c)-(e) (i.e., the best stepwise-selection model).\n",
    "kf = KFold(n=n, n_folds=numfolds, shuffle = True)\n",
    "MSE = 0\n",
    "for train_indices, test_indices in kf:\n",
    "    train_X = X.iloc[train_indices, :]; train_y = y[train_indices]\n",
    "    test_X = X.iloc[test_indices, :]; test_y = y[test_indices]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    m = smf.ols('Salary ~ CRBI + Hits + PutOuts + Division + AtBat + Walks + CWalks + CRuns + CAtBat + Assists', data = training).fit()   \n",
    "    pred = m.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE3 = np.sqrt(MSE/numfolds)\n",
    "print('The predictive RMSE for the best model selected by stepwise selection is ', round(RMSE3, 4))\n",
    "\n",
    "#iv. The model that is considered optimal with respect to the Bayesian Information Criterion (BIC) which contains the variables AtBat, Hits, Walks, CRBI, Division and PutOuts.\n",
    "kf = KFold(n=n, n_folds=numfolds, shuffle = True)\n",
    "MSE = 0\n",
    "for train_indices, test_indices in kf:\n",
    "    train_X = X.iloc[train_indices, :]; train_y = y[train_indices]\n",
    "    test_X = X.iloc[test_indices, :]; test_y = y[test_indices]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    m = smf.ols('Salary ~ AtBat + Hits + Walks + CRBI + Division + PutOuts', data = training).fit()   \n",
    "    pred = m.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE4 = np.sqrt(MSE/numfolds)\n",
    "print('The predictive RMSE for the optimal model (in terms of BIC) is ', round(RMSE4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the RMSE, the best predicitive model is the optimal BIC model since it has the smallest RMSE. In contrast, the worst predicitive model is the full model since it has the largest RMSE. And both the optimal model from part (b) and the stepwise selection mdoel perform similarly to the optimal BIC model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Given the estimates of predictive accuracy from parts (f) and (g) indicate which estimates you believe to be more accurate. In other words, indicate which validation approach (i.e., cross validation vs. k-fold cross validation) you believe will most accurately estimate the predictive capability of a model. Briefly explain your rationale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we see that the 10-fold cross validation uses all of the data provided and giving us a more accurate predictive model. Therefore, the k-fold corss validation estimates are more accurate than cross validation since k-cross validation follows the 80-20 parition we want instead of individual partitions like in cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Accounting for all of the analyses you‚Äôve performed (i.e., multicollinearity, goodness-of-fit, and predictive accuracy), which model would you be most comfortable using? Briefly justify your choice. [Note: I‚Äôm not looking for a right or wrong answer here; I want to see that you can sensibly and eloquently justify your choice]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd be more comfortable using the optimal BIC model since we see in part (g) that it is the best predictive model when using 10-fold cross validation which we discussed in (h) has the best accuracy over cross-validation results. Another reason for this decision is that the optimal BIC model is also protected from multicollinearity compared to other models. This protection comes from the model only containing one of the multicollinear explanatory varibales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
